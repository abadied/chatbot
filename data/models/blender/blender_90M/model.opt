{
    "init_opt": null,
    "show_advanced_args": false,
    "task": "internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues",
    "download_path": "/private/home/edinan/ParlAI/downloads",
    "datatype": "train",
    "image_mode": "raw",
    "numthreads": 1,
    "hide_labels": false,
    "multitask_weights": [
        1.0,
        3.0,
        3.0,
        3.0
    ],
    "batchsize": 16,
    "datapath": "/private/home/edinan/ParlAI/data",
    "model": "transformer/generator",
    "model_file": "/checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model",
    "init_model": "/checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model",
    "dict_class": "parlai.core.dict:DictionaryAgent",
    "evaltask": null,
    "eval_batchsize": null,
    "display_examples": false,
    "num_epochs": -1,
    "max_train_time": -1,
    "validation_every_n_secs": -1,
    "save_every_n_secs": 60.0,
    "save_after_valid": true,
    "validation_every_n_epochs": 0.25,
    "validation_max_exs": 20000,
    "short_final_eval": false,
    "validation_patience": 15,
    "validation_metric": "ppl",
    "validation_metric_mode": "min",
    "validation_cutoff": 1.0,
    "load_from_checkpoint": false,
    "validation_share_agent": false,
    "aggregate_micro": false,
    "metrics": "default",
    "tensorboard_log": false,
    "dict_maxexs": -1,
    "dict_include_valid": false,
    "dict_include_test": false,
    "log_every_n_secs": 2,
    "image_size": 256,
    "image_cropsize": 224,
    "label_type": "response",
    "include_knowledge": true,
    "include_checked_sentence": true,
    "include_knowledge_separator": false,
    "num_topics": 5,
    "train_experiencer_only": false,
    "embedding_size": 512,
    "n_layers": 8,
    "ffn_size": 2048,
    "dropout": 0.1,
    "attention_dropout": 0.0,
    "relu_dropout": 0.0,
    "n_heads": 16,
    "learn_positional_embeddings": true,
    "embeddings_scale": true,
    "n_positions": 512,
    "n_segments": 0,
    "variant": "xlm",
    "activation": "gelu",
    "output_scaling": 1.0,
    "share_word_embeddings": true,
    "beam_size": 10,
    "beam_min_length": 20,
    "beam_context_block_ngram": 3,
    "beam_block_ngram": 3,
    "beam_length_penalty": 0.65,
    "skip_generation": false,
    "inference": "beam",
    "topk": 10,
    "topp": 0.9,
    "compute_tokenized_bleu": false,
    "embedding_type": "random",
    "embedding_projection": "random",
    "fp16": true,
    "fp16_impl": "apex",
    "force_fp16_tokens": false,
    "optimizer": "adamax",
    "learningrate": 7.5e-06,
    "gradient_clip": 0.1,
    "adam_eps": 1e-08,
    "adafactor_eps": [
        1e-30,
        0.001
    ],
    "momentum": 0,
    "nesterov": true,
    "nus": [
        0.7
    ],
    "betas": [
        0.9,
        0.999
    ],
    "weight_decay": null,
    "rank_candidates": false,
    "truncate": -1,
    "text_truncate": 512,
    "label_truncate": 128,
    "history_size": -1,
    "person_tokens": false,
    "split_lines": false,
    "use_reply": "label",
    "add_p1_after_newln": false,
    "delimiter": "\n",
    "gpu": -1,
    "no_cuda": false,
    "dict_file": "/checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model.dict",
    "dict_initpath": null,
    "dict_language": "english",
    "dict_max_ngram_size": -1,
    "dict_minfreq": 0,
    "dict_maxtokens": -1,
    "dict_nulltoken": "__null__",
    "dict_starttoken": "__start__",
    "dict_endtoken": "__end__",
    "dict_unktoken": "__unk__",
    "dict_tokenizer": "bpe",
    "dict_lower": true,
    "bpe_debug": false,
    "dict_textfields": "text,labels",
    "lr_scheduler": "reduceonplateau",
    "lr_scheduler_patience": 3,
    "lr_scheduler_decay": 0.5,
    "max_lr_steps": -1,
    "invsqrt_lr_decay_gamma": -1,
    "warmup_updates": -1,
    "warmup_rate": 0.0001,
    "update_freq": 1,
    "parlai_home": "/private/home/edinan/ParlAI",
    "override": {
        "task": "internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues",
        "model": "transformer/generator",
        "multitask_weights": [
            1.0,
            3.0,
            3.0,
            3.0
        ],
        "init_model": "/checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model",
        "dict_file": "/checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model.dict",
        "embedding_size": 512,
        "n_layers": 8,
        "ffn_size": 2048,
        "dropout": 0.1,
        "n_heads": 16,
        "learn_positional_embeddings": true,
        "n_positions": 512,
        "variant": "xlm",
        "activation": "gelu",
        "skip_generation": true,
        "fp16": true,
        "text_truncate": 512,
        "label_truncate": 128,
        "dict_tokenizer": "bpe",
        "dict_lower": true,
        "learningrate": 7.5e-06,
        "optimizer": "adamax",
        "lr_scheduler": "reduceonplateau",
        "gradient_clip": 0.1,
        "validation_every_n_epochs": 0.25,
        "betas": [
            0.9,
            0.999
        ],
        "update_freq": 1,
        "attention_dropout": 0.0,
        "relu_dropout": 0.0,
        "validation_patience": 15,
        "save_every_n_secs": 60.0,
        "validation_max_exs": 20000,
        "batchsize": 16,
        "validation_metric": "ppl",
        "validation_metric_mode": "min",
        "save_after_valid": true,
        "model_file": "/checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model"
    },
    "starttime": "Feb10_07-25",
    "batchindex": 15
}
